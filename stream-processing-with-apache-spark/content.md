# 目录

- [第1部分 使用Apache Spark进行流处理的基础知识](#part-1)
    - [第1章 流处理简介](#chapter-1)


# <span id="part-1">第1部分 使用Apache Spark进行流处理的基础知识</span>

本书的第一部分致力于为流处理的概念和理解`Apache Spark`作为流引擎的理论奠定坚实的基础。

我们首先讨论当今企业采用流处理技术和系统背后的动机（第1章）。然后，我们建立流处理通用的词汇和概念（第2章）。接下来，我们讨论不同流架构的最新进展（第3章），并概述对`Apache Spark`作为流处理引擎的理论理解（第4章）。

如果想看具体的内容，读者可以直接跳到第二部分的`Structed Streaming`或第三部分的`Spark Streaming`。

对于那些喜欢在使用之前有更深了解的人，我们建议您在第5章中继续阅读Spark的分布式处理模型，其中我们奠定了核心概念，这些概念稍后将帮助您更好地了解`Spark Streaming`和`Structured Streaming`提供的不同的实现，选项和功能。

在第6章中，我们深入理解Spark所实现的弹性模型，以及它如何减轻开发人员的痛苦，实现运行7*24全天候企业关键工作负载的强大流应用程序。

有了这些新知识，我们准备使用Spark的两个流API，我们将在本书的后续部分中进行介绍。

<div STYLE ="page-break-after：always;"> </div>

## <span id="chapter-1">第1章 流处理简介</span>

2011年，马克·安德森（Marc Andreessen）有句著名的话：“软件正在吞噬整个世界”，指的是蓬勃发展的数字经济，当时许多企业都面临着数字转型的挑战。使用“在线”和“移动”操作模式的在线业务正在接管传统的“实体店”。

例如，想象一下在照相馆里购买新相机的传统经验：我们会去照相馆逛逛，也许会问店员几个问题，下定决心，最后购买一个能满足我们要求的相机。购买完成后，商店将使用信用卡或现金进行交易，商店经理会知道他们的特定相机型号的库存减少了。

现在，让我们在线上体验一下：首先，我们开始搜索网络。我们访问了几个在线商店，当我们从一个地方转移到另一个地方时，留下了数字痕迹。网站上的广告突然开始向我们展示我们正在寻找的相机以及其他竞争产品的促销。我们终于找到了一家网上商店，为我们提供最优惠的价格并购买相机。我们会创建一个帐户。我们的个人数据会关联到购买记录。当我们完成购买后，网上商店会为我们提供其他选项，并告诉我们这些选项在购买同一相机的其他人中很受欢迎。我们的每次数字互动，例如在网络上搜索关键字，单击某些链接或花时间阅读特定页面，都会生成一系列事件，这些事件被收集并转化为业务价值，例如个性化广告或促销建议。

Dries Buytaert在2015年评论Andreessen的话时说：“实际上，数据正在吞噬整个世界。” 他的意思是，当今具有颠覆性的公司不再因为其软件，而是因为他们收集的独特数据以及将这些数据转化为价值的能力。

流处理技术的采用是由企业不断增长的需求推动的，企业需要缩短适应运营环境变化所需的时间。这种处理数据的方式提供了技术和战略优势。采用这种技术的例子包括：电子商务、连续运行的数据管道，这些数据管道是由与客户全天候互动的企业创建的，或者信用卡公司，在交易发生时进行分析，以便在欺诈活动发生时发现并制止。

流处理的另一个驱动因素是，我们生成数据的能力远远超过理解数据的能力。我们在个人和专业环境中不断增加具有计算能力的设备，如电视机、联网汽车、智能手机、自行车电脑、智能手表、监控摄像头、恒温器等。我们周围都是用来生成事件日志的设备：表示设备上下文中的动作和意外事件的消息流，这些动作和意外事件构成了设备历史的一部分。随着这些设备的互联越来越多，我们可以访问并分析这些事件日志。这种现象为近实时数据分析领域的创新打开了一扇令人难以置信的大门，前提是我们找到了一种使这种分析易于处理的方法。在这个聚集事件日志的世界中，流处理提供了最友好的方式来简化数据流的分析。

不仅数据正在吞噬世界，而且流式数据也在吞噬世界。

在本章中，我们将开始`Apache Spark`进行流处理的旅程。为了讨论`Spark`在流处理领域的能力，我们需要对什么是流处理、它的应用和它的挑战有一定的理解。在构建了该公共语言之后，我们将介绍`Apache Spark`，这是一个通用的数据处理框架，能够使用统一的模型处理批处理和流式处理。最后，我们将详细介绍`Spark`的流处理功能，其中我们将介绍两种流处理方式：`Spark Streaming`和`Structured Streaming`。我们简要地讨论了它们的显著特征，以便让您可以在本书的其余部分对它们有一个清晰的了解。

### 什么是流处理

流处理是从无限数据中提取信息的技术。

Tyler Akidau在他的`Streaming Systems`一书中对无限数据的定义如下：

`A type of dataset that is infinite in size (at least theoretically).`

考虑到我们的信息系统是建立在内存和存储容量等有限资源的硬件上的，它们不可能容纳无限的数据集，相反，我们在处理系统以事件流的形式接收数据，并随着时间的推移观察数据。我们称之为数据流。

另一方面，我们认为有界数据是一个已知大小的数据集。我们可以计算有界数据集中元素的数量。

### 批处理与流处理

我们如何处理这两种类型的数据集？对于批处理，我们指的是有界数据集的计算分析。在实践中，这意味着这些数据集作为一个整体可以从某种形式的存储中获得。我们在计算过程开始时就知道数据集的大小，而且计算过程的持续时间是有限的。

与此相反，在流处理中，我们关注的是数据到达系统时的处理。由于数据流的无界性质，流处理器需要持续运行，只要流还在传递新数据。正如我们所了解到的，这在理论上可能是永远的。

流处理系统应用编程和操作技术，使在有限的计算资源下处理潜在的无限数据流成为可能。

### 流处理中的时间概念

数据有两种形式：

- 静态数据，以文件的形式，数据库的内容，或其他类型的记录
- 动态数据，作为连续生成的信号序列，如传感器的测量或移动车辆的GPS信号

我们已经讨论过流处理程序是一个假定其输入可能是无限大的程序。更具体地说，流处理程序假设它的输入是一系列不确定长度的信号，随着时间的推移而观察到。

从时间轴的角度来看，静态数据是来自过去的数据:可以说，所有有边界的数据集，无论是存储在文件中还是包含在数据库中，最初都是随着时间推移收集到一些存储中的数据流。用户的数据库、上季度的所有订单、城市出租车行程的GPS坐标等等，都以收集在存储库中的单个事件开始。

试图对动态数据进行推理则更具挑战性。在数据生成的时间和系统处理时间之间有时间差?这个时间差可能非常短，就像在同一个数据中心中生成和处理的web日志事件，也可能更长，就像一辆通过隧道的汽车的GPS数据，只有在汽车离开隧道后重新建立无线连接时才会发送。

我们可以看到有两条时间轴：事件产生的时间轴和被流处理系统处理的时间轴。这些时间轴非常重要，所以我们给它们起了特定的名字：

- 事件时间

    事件产生的时间。时间信息由产生事件的设备的本地时钟提供。

- 处理时间

    流处理系统处理事件的时间。这是运行处理逻辑的服务器的时钟。它通常与技术原因有关，比如计算处理延迟或确定重复输出

当我们需要关联、排序或聚合事件时，这些时间线之间的差异就变得非常重要。


### 不确定性因素

在时间轴上，静态数据与过去有关，而动态数据可以被视为现在。但是未来呢?这个讨论的一个最微妙的方面是，它没有对系统接收事件时的吞吐量做任何假设。

一般来说，流处理系统不需要输入以固定的时间间隔产生，也不需要同时产生，也不需要遵循一定的节奏。这意味着，预测峰值负载是一个挑战:如何将输入元素的突然到来与处理它们所需的计算资源相匹配。

如果我们有足够的计算能力来匹配突发的输入数据，我们的系统将产生预期的结果，但如果我们没有预计到这样突发的数据，一些流处理系统可能会面临延迟、资源限制和故障。

处理不确定性是流处理的一个重要方面。

总之，流处理让我们可以从无限的数据流中提取信息，这些数据流是随着时间的推移被观察到的事件。然而，当我们接收和处理数据时，我们需要处理事件时间的额外复杂性和无限输入所带来的不确定性。

我们为什么要处理额外的麻烦?在下一节中，我们将回顾一些用例，这些用例说明了流处理的价值及可行性，从而在数据中找到业务价值。

### 流处理用例

下面的用例只是一个很小的示例，我们用它来说明流处理的广泛应用：

- 设备监控

    一家小型初创公司推出了一款基于云计算的物联网(IoT)设备，可用于收集、处理和存储多达1000万台设备的数据。多个流处理器被部署到应用程序的不同部分，从使用内存存储的实时仪表盘，到连续的数据聚合，如去重计数和最小/最大测量。

- 故障检测

    大型硬件制造商应用复杂的流处理管道来接收设备指标。使用时间序列分析，潜在的故障被发现，纠正措施被自动发送回设备。

- 计费

    一家成熟的保险公司将其账单系统转移到了流式管道。从原来的批量处理到现在实时处理。

- 车队管理

    车队管理公司安装了能够报告被管理车辆的实时数据的设备，如位置、电机参数和燃油水平，使其能够执行地理限制等规则，并分析司机在限速方面的行为。

- 媒体推荐

    一家全国性的媒体公司部署了一个流媒体管道，将新视频(如新闻报道)输入其推荐系统，使得用户几乎在视频被输入该公司的媒体库后，就可以为其提供个性化的建议。该公司之前的系统需要数小时才能做到这一点。

- 贷款审批

    通过将多个数据流合并到一个流应用程序中，拥有贷款服务的银行能够将贷款批准从数小时减少到数秒。

这些用例中的一个共同主线是业务需要处理数据，并在接收数据后的短时间内可得到结果。这段时间与用例相关:虽然几分钟对于贷款审批来说是非常快的时间周期，但是在给定的服务级别阈值内，检测设备故障并发出纠正操作可能需要几毫秒的响应。

在任何情况下，我们都可以说，尽可能快地使用数据会更好。

现在，我们已经了解了什么是流处理，以及今天如何使用流处理的一些例子，是时候深入研究支撑流处理实现的概念了。

### 扩展数据处理

在我们讨论流处理中分布式计算的含义之前，让我们先快速浏览一下MapReduce，这是一种计算模型，它为可伸缩和可靠的数据处理奠定了基础

#### MapReduce

分布式系统编程的历史在2003年2月经历了一个值得注意的事件。Jeff Dean和Sanjay Gemawhat，在经历了几次重写谷歌的爬虫和索引系统之后，开始注意到一些操作有共通之处。这使得他们开发了mapreduce，一种在谷歌里用于大型集群分布式处理的系统。

```
我们没有更早开发MapReduce的部分原因可能是，当我们在更小的规模上运行时，我们的计算使用更少的机器，因此健壮性并不是那么重要:定期检查一些计算并在机器死机时重新启动整个计算是很好的。然而，一旦你达到一定规模，这就变得相当站不住脚了，因为你总是重新开始，永远不会取得任何进展。
    —Jeff Dean, email to Bradford F. Lyon, August 2013
```

`MapReduce`首先是一个编程API，其次是一组组件，它使分布式系统的编程工作相对简单。

它的核心原则是两个函数:

- map

    map操作以一个函数作为参数，应用于集合的每个元素。集合的元素从分布式文件系统中读取，每个执行器一次读取一个块。然后，函数将应用于块中的所有元素，执行程序将输出该应用程序的结果。

- reduce

    reduce操作有两个参数:一个是当传递的是空集合时，返回什么。另一个是聚合操作，它对集合中的元素进行聚合。

这两个高阶函数的组合足以表达我们想在数据集上执行的每一个操作。

#### 经验教训:可伸缩性和容错

从程序员的角度来看，`MapReduce`的主要优点是:

- 简单的API。
- 它提供了非常高的表现力。
- 应用开发人员不必关系分布式系统的难点，而交给库设计者。


尽管这些特点使该模式具有吸引力，但`MapReduce`的主要成功之处在于其维持增长的能力。随着数据量的增加和不断增长的业务需求导致了更多的信息提取工作，MapReduce模型展示了两个关键属性：

- 可扩展性

    随着数据集的增长，可以向机器集群添加更多的资源，以保持稳定的处理性能。

- 容错

    系统能够维持部分故障并从部分故障中恢复。所有数据是冗余的。如果携带数据的执行程序崩溃了，重新启动在崩溃的执行程序上运行的任务就足够了。因为主节点会跟踪该任务，所以除了重新调度之外，不会产生任何特殊问题。

这两个特性结合在一起，使得系统能够在一个根本不可靠的环境中持续维持工作负载，流处理也需要这些属性。

### 分布式流处理

使用`MapReduce`模型的流处理和使用批处理的一个基本区别是，批处理可以访问完整的数据集，但是流处理，我们在任何时候都只能看到数据集的一小部分。

这种情况在分布式系统中更加严重。也就是说，为了在一系列执行器中分配处理负载，我们进一步将输入流划分为多个分区。每个执行器只能看到完整流的部分视图。

分布式流处理框架面临的挑战是提供一个抽象，向用户隐藏这种复杂性，并让我们从整体上对流进行推理。

#### 分布式系统中的有状态流处理

让我们想象一下，我们正在清点总统选举的选票。经典的批处理方法是等待，直到所有的选票都被投出，然后继续计数。即使这种方法产生了一个正确的最终结果，它也会在当天造成非常无聊的新闻，因为直到选举过程结束后才知道结果。

一个更令人兴奋的场景是，我们可以将每个候选人的选票计算为每一张选票。在任何时候，我们都有参与者的部分计票，让我们看到当前的状况和投票趋势。我们或许可以预料到结果。

为了完成这个场景，流处理器需要内部寄存器保存到目前为止看到的投票。要确保计数一致，此寄存器必须能从多个部分失败中恢复。事实上，我们不能因为技术故障要求公民再次投票。

另外，任何故障恢复都不会影响最终结果。我们不能宣布出现一个错误的获胜候选人是因为一个恢复不良的系统。

这个场景说明了在分布式环境中运行有状态流处理所面临的挑战。有状态处理给系统带来了额外的负担：

- 我们需要确保状态随着时间的推移而保持。
- 我们要求数据一致性保证，即使在部分系统故障的情况下

正如您将在本书中看到的，解决这些问题是流处理的一个重要方面。

现在我们已经对流处理流行背后的驱动因素和这一学科的挑战性有了更好的认识，我们可以引入`Apache Spark`。作为一个统一的数据分析引擎，`Spark`为批处理和流处理提供了数据处理能力，这使它成为满足数据密集型应用程序需求的一个极好的选择。

### Apache Spark简介

`Apache Spark`是一个快速、可靠、容错的分布式计算框架，可用于大规模数据处理。

#### 函数式API

在早期，`Spark`是由其对内存和超强表达能力的函数式API的闻名的。Spark内存模型使用RAM来缓存正在处理的数据，从而使处理速度比`Hadoop MapReduce`快100倍，`Hadoop MapReduce`是谷歌的`MapReduce`的开源实现，用于批处理工作负载。

它的核心抽象，弹性分布式数据集(RDD)，带来了一个丰富的函数式编程模型，抽象出了集群上分布式计算的复杂性。它引入了转换和操作的概念，这些概念提供了比我们在`MapReduce`概述中讨论的map和reduce阶段更具表达性的编程模型。在这个模型中，许多可用的转换，如map、flatmap、join和filter表示数据从一种内部表示到另一种内部表示的惰性转换，而称为动作的操作则在分布式系统上实现计算以产生结果。

#### SQL

`Spark`项目历史上的第二个改变者是`Spark SQL`和`DataFrames`(以及后来的Dataset，一种强类型的DataFrame)的引入。从高级的角度来看，`Spark SQL`将SQL支持添加到任何具有模式的数据集。它使查询逗号分隔值(CSV)、Parquet或JSONdataset成为可能，就像我们用于查询SQL数据库的方式一样。

这种演变也降低了用户采用的门槛。高级分布式数据分析不再是软件工程师的专属领域;现在，数据科学家、业务分析师和其他熟悉sql的专业人士都可以访问它。从性能的角度来看，`Spark SQL`为`Spark`带来了查询优化器和物理执行引擎，使其在使用更少资源的情况下运行更快。

### 统一的引擎

现在，`Spark`是一个统一的分析引擎，提供批处理和流处理能力，兼容多语言的数据分析方法，提供scala、Java、Python和R语言的api。

虽然在本书的上下文中，我们将重点关注`Apache Spark`的流处理功能，但它的批处理功能同样先进，并且是对流应用程序的高度补充。`Spark`的统一编程模型意味着开发人员只需要学习一种新的范式就可以同时处理批处理和流处理工作负载。

### Spark组件

图1-1说明了`Spark`由核心引擎、构建在其之上的一组抽象(表示为水平层)和使用这些抽象来处理特定区域(垂直框)的库组成。高亮区域是这本书的内容，而那些没有被覆盖的区域用灰色表示。要了解更多关于`Apache Spark`的其他领域，我们推荐Spark、Bill Chambers和Matei Zaharia (O 'Reilly)的`The Definitive Guide`，以及holden Karau和Rachel Warren (O 'Reilly)的`High Performance Spark`。

![图1-1](../img/figure-1-1.png)


以下是Spark中的抽象层：

- Spark Core

    包含`Spark`核心执行引擎和一组用于将计算分配到一个计算资源集群的低级别功能性api，在`Spark`行话中称为executors。它的集群抽象允许它将工作负载提交给YARN、Mesos和Kubernetes，也可以使用自己的独立集群模式，在这种模式下，spark作为一个专用服务运行在一个机器集群中。它的数据源抽象能够集成许多不同的数据提供者，如文件、区块存储、数据库和事件代理。

- Spark SQL

    实现`Spark`的高级Dataset和DataFrame api，并在任意数据源上添加sql支持。它还介绍了一系列通过`Catalyst`查询引擎的性能改进，以及`Tungsten`项目的代码生成和内存管理。

构建在这些抽象之上的库解决了大规模数据分析的不同领域:用于机器学习的MLLib，用于图形分析的GraphFrames，以及用于流处理的两个api，这是本书的重点:`Spark Streaming`和`Structured Streaming`。

### Spark Streaming

`Spark Streaming`是第一个建立在`Spark`核心引擎之上的流处理框架。它是在2013年2月的Spark 0.7.0版本中作为alpha版本引入的，经过一段时间的发展，现在已经成为一个成熟的API，业界广泛采用它来处理大规模数据流。

`Spark Streaming`的概念建立在一个简单而强大的前提之上:通过将连续的数据流转换为离散的数据集合，将`Spark`的分布式计算能力应用到流处理中。这种流处理方法被称为微批处理模型;这与在大多数其他流处理工具中占主导地位的`element-at-time`模型形成了对比。

`Spark Streaming`使用与`Spark`核心相同的函数式编程范式，但是它引入了一个新的抽象，离散流或DStream，它公开了一个编程模型来操作流中的底层数据。

### Structured Streaming

`Structured Streaming`是构建在`Spark SQL`抽象之上的流处理器。它通过流功能扩展了Dataset和DataFrame api。因此，它采用了面向schema的转换模型，该模型赋予了其名称的结构化部分，并继承了在`Spark SQL`中实现的所有优化。

2016年7月，Spark 2.0引入了`Structured Streaming`作为实验性API。一年后，随着Spark 2.2发行版的发布，它达到了普遍可用性，成为生产部署的合格条件。作为一个相对较新的发展，`Structured Streaming`仍在每一个新版本的`Spark`中快速发展的。

`Structured Streaming`使用声明式模型从一个流或一组流中获取数据。要充分使用API，需要为流中的数据指定schema。除了支持Dataset和DataFrame api提供的通用转换模型之外，它还引入了特定于流的特性，如对事件时间、流连接和底层runtime分离的支持。最后一个特性为实现不同执行模型的runtime打开了大门。默认实现使用经典的微批处理方法，而最近的连续处理后端带来了对近实时连续执行模式的实验性支持。

`Structured Streaming`提供了一个统一的模型，将流处理带到面向批处理的应用程序的同一级别，消除了大量关于流处理推理的认知负担。

### 下一站？

如果你想马上学习这两个api中的任何一个，你可以直接跳到第二部分的`Structured Streaming`或者第三部分的`Spark Streaming`。如果您不熟悉流处理，我们建议您继续阅读本书的第一部分，因为我们将构建讨论特定框架时使用的词汇表和公共概念。

<div STYLE ="page-break-after：always;"> </div>