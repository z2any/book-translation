


# 第一部分 使用Apache Spark进行流处理的基础知识

本书的第一部分致力于为流处理的概念和Apache Spark作为流引擎的理论理解奠定坚实的基础。

我们首先讨论当今企业采用流处理技术和系统背后的动机（第1章）。然后，我们建立流处理通用的词汇和概念（第2章）。接下来，我们讨论不同流架构的最新进展（第3章），并概述对Apache Spark作为流引擎的理论理解（第4章）。

读者可以直接跳到第二部分的`Structed Streaming`或第三部分的`Spark Streaming`，看看更实际的讨论。

对于那些喜欢在进入API和运行时内容之前先加深了解的人，我们建议您在第5章中继续阅读Spark的分布式处理模型，其中我们奠定了核心概念，这些概念稍后将帮助您更好地了解`Spark Streaming`和`Structured Streaming`提供的不同的实现，选项和功能。

在第6章中，我们加深了对Spark所实现的弹性模型的理解，以及它如何减轻开发人员的痛苦，以实现可运行24/7全天候企业关键工作负载的强大流应用程序。

有了这些新知识，我们准备使用Spark的两个流API，我们将在本书的后续部分中进行介绍。

<div STYLE ="page-break-after：always;"> </div>

##  第一章 流处理简介

2011年，马克·安德森（Marc Andreessen）有句著名的话：“软件正在吞噬整个世界”，指的是蓬勃发展的数字经济，当时许多企业都面临着数字转型的挑战。使用“在线”和“移动”操作模式的成功在线业务正在接管传统的“实体店”。

例如，想象一下在照相馆里购买新相机的传统经验：我们会去照相馆逛逛，也许会问店员几个问题，下定决心，最后购买一个能满足我们要求的相机。购买完成后，商店将使用信用卡或现金进行交易，商店经理会知道他们的特定相机型号的库存减少了。


<div STYLE ="page-break-after：always;"> </div>